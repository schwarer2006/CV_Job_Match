{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmeEsONQWnT6jeQZ72aRAL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schwarer2006/CV_Job_Match/blob/main/Komplexes_JOB_CV_Script_pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "Um7ILJgHNZRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import re\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "from datetime import datetime\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def load_text(file_path):\n",
        "    \"\"\"Loads and cleans text from a given file path.\"\"\"\n",
        "    if file_path.endswith('.pdf'):\n",
        "        text = []\n",
        "        with pdfplumber.open(file_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text.append(page_text)\n",
        "        text = ' '.join(text) if text else ''\n",
        "    else:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "def tokenize_and_remove_stopwords(text):\n",
        "    \"\"\"Tokenizes text and removes German stopwords.\"\"\"\n",
        "    stop_words = set(stopwords.words('german'))\n",
        "    tokens = word_tokenize(text)\n",
        "    return [word for word in tokens if word not in stop_words]\n",
        "\n",
        "def calculate_cosine_similarity(text1, text2):\n",
        "    \"\"\"Calculates cosine similarity between two texts.\"\"\"\n",
        "    vectorizer = CountVectorizer()\n",
        "    vectors = vectorizer.fit_transform([text1, text2]).toarray()\n",
        "    return cosine_similarity(vectors)[0][1]\n",
        "\n",
        "def save_visualizations_to_pdf(similarity_score, name, vorname, stellenname, firma, resume_text, job_description_text, resume_tokens, job_description_tokens):\n",
        "    \"\"\"Saves various text analysis visualizations to a PDF file.\"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    pdf_path = f'/content/visualizations_{name}_{vorname}_{timestamp}.pdf'\n",
        "    score_color = 'red' if similarity_score <= 0.50 else 'green'\n",
        "\n",
        "    with PdfPages(pdf_path) as pdf:\n",
        "        # Personal and match data on one page\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        ax.text(0.5, 0.6, f\"Name: {name}\\nVorname: {vorname}\\nStellenname: {stellenname}\\nFirma: {firma}\\nDatum: {datetime.now().strftime('%d.%m.%Y')}\",\n",
        "                fontsize=12, ha='center', va='center', transform=ax.transAxes)\n",
        "        ax.text(0.5, 0.5, f\"Ãœbereinstimmung: {similarity_score * 100:.2f}%\", fontsize=12, ha='center', va='center', color=score_color, transform=ax.transAxes)\n",
        "        ax.axis('off')\n",
        "        pdf.savefig(fig)\n",
        "        plt.close(fig)\n",
        "\n",
        "        # Additional plots (Wordclouds and Bar Charts)...\n",
        "        # Wordclouds for both texts\n",
        "        for text, title in [(resume_text, 'Lebenslauf Wordcloud'), (job_description_text, 'Stellenbeschreibung Wordcloud')]:\n",
        "            wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "            fig, ax = plt.subplots(figsize=(8, 4))\n",
        "            ax.imshow(wordcloud, interpolation='bilinear')\n",
        "            ax.set_title(title)\n",
        "            ax.axis('off')\n",
        "            pdf.savefig(fig)\n",
        "            plt.close(fig)\n",
        "\n",
        "        # Word frequency bar charts\n",
        "        for tokens, title in [(resume_tokens, 'Lebenslauf Wortfrequenz'), (job_description_tokens, 'Stellenbeschreibung Wortfrequenz')]:\n",
        "            fig, ax = plt.subplots(figsize=(8, 6))\n",
        "            word_freq = Counter(tokens)\n",
        "            df = pd.DataFrame(word_freq.most_common(20), columns=['Word', 'Frequency'])\n",
        "            sns.barplot(x='Frequency', y='Word', data=df, ax=ax, palette='viridis')\n",
        "            ax.set_title(title)\n",
        "            pdf.savefig(fig)\n",
        "            plt.close(fig)\n",
        "\n",
        "        # Radar Plot for Skill Comparison\n",
        "        common_tokens = set(resume_tokens) & set(job_description_tokens)\n",
        "        resume_freq = Counter(resume_tokens)\n",
        "        job_desc_freq = Counter(job_description_tokens)\n",
        "        radar_data = {token: [resume_freq[token], job_desc_freq[token]] for token in common_tokens}\n",
        "        df = pd.DataFrame(radar_data, index=['Resume', 'Job Description']).T\n",
        "        angles = np.linspace(0, 2 * np.pi, len(common_tokens), endpoint=False).tolist()\n",
        "        fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))\n",
        "        ax.fill(angles, df['Resume'], color='red', alpha=0.25)\n",
        "        ax.fill(angles, df['Job Description'], color='green', alpha=0.25)\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_xticks(angles)\n",
        "        ax.set_xticklabels(df.index, rotation=45, fontsize=8)\n",
        "        pdf.savefig(fig)\n",
        "        plt.close(fig)\n",
        "\n",
        "\n",
        "    print(f\"PDF saved at: {pdf_path}\")\n",
        "\n",
        "input_type = input(\"Enter the type of input for job description (1 - Text File, 2 - PDF File): \")\n",
        "if input_type == '1':\n",
        "    job_description_path = input(\"Enter the path to the text file for job description: \")\n",
        "elif input_type == '2':\n",
        "    job_description_path = input(\"Enter the path to the PDF file for job description: \")\n",
        "else:\n",
        "    print(\"Invalid input. Please restart the script and enter 1 or 2.\")\n",
        "    exit()\n",
        "\n",
        "job_description_text = load_text(job_description_path)\n",
        "job_description_tokens = tokenize_and_remove_stopwords(job_description_text)\n",
        "\n",
        "# Input fields for resume and personal details\n",
        "resume_path = input(\"Enter the path to your resume (text or PDF): \")\n",
        "resume_text = load_text(resume_path)\n",
        "resume_tokens = tokenize_and_remove_stopwords(resume_text)\n",
        "similarity_score = calculate_cosine_similarity(' '.join(resume_tokens), ' '.join(job_description_tokens))\n",
        "\n",
        "name = input(\"Enter your last name: \")\n",
        "vorname = input(\"Enter your first name: \")\n",
        "stellenname = input(\"Enter the job title: \")\n",
        "firma = input(\"Enter the company name: \")\n",
        "\n",
        "save_visualizations_to_pdf(similarity_score, name, vorname, stellenname, firma, resume_text, job_description_text, resume_tokens, job_description_tokens)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrWULAYRX6BA",
        "outputId": "0dfbd77d-da1d-40cc-c35f-7b0b2028b60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the type of input for job description (1 - Text File, 2 - PDF File): 1\n",
            "Enter the path to the text file for job description: /content/stellenbeschreibung.txt\n",
            "Enter the path to your resume (text or PDF): /content/kenntnisse.txt\n",
            "Enter your last name: Schwarz\n",
            "Enter your first name: Erik\n",
            "Enter the job title: BI Developer\n",
            "Enter the company name: PostFinance\n",
            "PDF saved at: /content/visualizations_Schwarz_Erik_2024-05-22_08-33-00.pdf\n"
          ]
        }
      ]
    }
  ]
}